---
title: "Frequentist and Bayesian Logistic Regression for Loan Repayment Analysis"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
options(digits = 3)
```

# To Start

In this section, we want to analyze factors associated with loan
repayment, so we are performing our analyses on the `loans.csv` data
set. The statistical method we would use here is regression. Regression
analysis is a predictive modelling technique that analyzes the relation
between the dependent variable(s) and the independent variable(s) in a
dataset. There are many types of regressions, and which one(s) to use
depends upon a number of factors: the type of dependent variable, the
number of independent variables, the pattern of dependent vs.
independent variables, the shape of the regression line, etc. We will
decide which type of regression to use after we dive deeper into our
data.

First, we read the dataset into our R environment:

```{r}
loans <- read.csv("data/loans.csv")
```

Next, in order to perform our statistical analysis, we load all the
packages needed using the `library()` function (in practice, which
packages to use will be decided as you proceed with your analyses,
rather than determined before starting):

```{r}
library(tidyverse)
library(loo)
library(countrycode)
library(broom)
library(kableExtra)
library(pROC)
library(rstanarm)
library(bayesplot)
```

There are eight core $\texttt{Tidyverse}$ packages namely
$\texttt{ggplot2}$, $\texttt{dplyr}$, $\texttt{tidyr}$,
$\texttt{readr}$, $\texttt{purrr}$, $\texttt{tibble}$,
$\texttt{stringr}$, and $\texttt{forcats}$. In our analysis we are using
$\texttt{dplyr}$ for data manipulations and $\texttt{ggplot2}$ for
graphics. The $\texttt{loo}$ package allows us to compute efficient
approximate leave-one-out cross-validation for fitted Bayesian models.
$\texttt{pROC}$ is for displaying and analyzing ROC curves.
$\texttt{rstanarm}$ is an appendage to the $\texttt{rstan}$ package, the
R interface to Stan which features an expressive probabilistic
programming language for specifying Bayesian models backed by extensive
math and algorithm libraries to support automated computation. The
$\texttt{bayesplot}$ package offers a variety of plots of posterior
draws, visual MCMC diagnostics, and graphical posterior predictive
checkings. Packages $\texttt{broom}$ and $\texttt{kableExtra}$ are used
here to display messy output of models into clear tables.

```{r eval=FALSE, echo=FALSE}
percent <- training %>% 
  drop_na(sector) %>% # drop missing values by health variable
  group_by(sector) %>%  # specify categorical variable
  summarize(Frequency = n()) %>% # return counts / frequencies
  mutate(Percent = paste0(round(Frequency / nrow(training) * 100, 2), "%"))

table <- kbl(percent, 
    caption = "Table 2: Frequency table for loan sectors") %>%
    kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")
table
colourCount = length(unique(loans$sector))
getPalette = colorRampPalette(brewer.pal(12, "Set3"))
bar <- ggplot(data = percent, aes(x = reorder(sector, Frequency), y = Frequency)) +
  geom_col(aes(fill = getPalette(colourCount)) , show.legend = FALSE) +
  ggtitle(paste("Loan Sector Distribution")) +
  coord_flip() 
bar
```

```{r eval=FALSE, echo=FALSE}
status <- loans %>% 
  drop_na(status) %>% # drop missing values by health variable
  group_by(status) %>%  # specify categorical variable
  summarize(Frequency = n()) %>% # return counts / frequencies
  mutate(Percent = paste0(round(Frequency / nrow(loans) * 100, 2), "%"))

table1 <- tibble(status) %>% 
  arrange(desc(Percent))
table1
donut1 <- ggplot(status, aes(x = 2, y = Frequency, fill = status)) +
    geom_bar(stat = "identity") +
    coord_polar(theta = "y", start = 0) + 
    theme_void() + # these theme removes the lines around chart and grey background
    theme(legend.title = element_text(size = 12),
          legend.text = element_text(size = 12)) +
    scale_fill_brewer(palette="Accent") +
    labs(fill = "Status Distribution") +
    xlim(0.5, 2.5)
donut1
bar1 <- ggplot(loans, aes(x = status)) +
  geom_bar() +
  coord_flip()
bar
```

```{r eval=FALSE, echo=FALSE}
ggplot(data = loan, aes(x = funded_amount)) +
  geom_histogram(binwidth=100) +
  labs(title="Distribution of Funded Amount")

ggplot(data = loan, aes(x = paid_amount)) +
  geom_histogram(binwidth=100) +
  labs(title="Distribution of Paid Amount")

ggplot(loan, aes(x = posted_yr)) +
  geom_histogram()
```

```{r eval=FALSE, echo=FALSE}
loan %>%
  count(status, sector) %>%       
  group_by(status) %>%
  mutate(pct= prop.table(n) * 100) %>%
  ggplot() + aes(status, pct, fill=sector) +
  geom_bar(stat="identity") +
  labs(x = "Status", y = "Proportion") +
  coord_flip() 
```

```{r eval=FALSE, echo=FALSE}
#continent
ggplot(data=d, aes(x = fct_infreq(continent),  fill=continent)) +
  geom_bar(stat = 'count') +
  scale_fill_brewer(palette = "Accent") +
  labs(x = "Continent")

ggplot(data=d, aes(x = status)) +
  geom_bar(aes(fill=as.factor(continent)), position="fill") +
  scale_fill_brewer(palette = "Accent")

#sector
ggplot(data=d, aes(x = status)) +
  geom_bar(aes(fill=as.factor(sector)), position="fill") 

#loan_amount
ggplot(d, aes(x = loan_amount, group = status)) +
  geom_boxplot()
  #geom_boxplot(outlier.colour="red", outlier.shape=8, outlier.size=4)
```

# Logistic Regression

The response of interest is the loan repayment status, recorded in the
`status` column of the `loans` data set. It is a categorical variable
with 8 levels: "paid", "refunded", "defaulted", "in_repayment",
"expired", "inactive", "fundraising", and "funded". Intuitively, for
such a categorical response variable, one appropriate model would be a
multinomial logistic regression which allows for more than two
categories of the response variable. However, the interpretation of
results is not as straightforward in such a model - and since the prompt
is explicitly concerned with loan default, a more interpretable model
would be one which dichotomizes the data to contrast defaulted and
non-defaulted loans.

To achieve this, we restrict the dataset to completed loans, which are
either repaid or not repaid. With a binary response variable, we can
utilize a binary logistic regression. (We are not using a linear
regression because it can generates predictions larger than 1 or smaller
than 0 which are not sensible for classification since the true
probability must fall between 0 and 1; also, linear regression assumes
normal errors, which is not the case for a Bernoulli variable).

The logistic regression model is an example of a broad class of models
known as generalized linear models (GLM). GLM's extend ordinary least
squares regression to response variables from arbitrary distributions
through the use of a link function; instead of the response varying
linearly with the covariates, its link function does. In this case, our
response is a binary variable and so the Bernoulli model is appropriate.
The Bernoulli distribution is a discrete probability distribution of a
random variable which takes the value 1 with probability $p$ and the
value 0 with probability $q=1-p$.The likelihood for one observation $y$
can be written as a Bernoulli PMF over possible outcomes $k$:
$$\begin{equation}
    f(k;p) =
    \left\{
        \begin{array}{cc}
                p & \mathrm{if\ } k=1 \\
                1-p & \mathrm{if\ } k=0 \\
        \end{array} 
    \right.
\end{equation},$$

The two most common link functions used for binomial GLMs are the logit
and probit functions. For binary outcomes a common choice is the *logit
link.* The logit link converts probabilities to log odds, and therefore
the model coefficients can be easily interpreted in terms of odds
ratios. When the logit link function is used the model is often referred
to as a logistic regression model (the inverse logit function is the CDF
of the standard logistic distribution).

The frequentist approach assumes data are random sample and parameters
are fixed while the Bayesian approach assumes both data and parameters
are random. The Bayesian analysis uses prior knowledge of the parameters
and the conditional distribution of the data given the parameters to be
employed to find the posterior distributions of the parameters given the
observed data. We would introduce the general procedures of these two
approaches In this section, we would apply two approaches of logistic
regression: frequentist and Bayesian, and compare the results.

## Data Preparation

### Response Variable

We set the `status` variable to be 1 if the loan status is and 0 if it
is "defaulted", such that we know the negative class is "defaulted" and
the positive class is "paid".

```{r}
d <- loans %>% 
  filter(status == "paid"|status == "defaulted")
d <- d %>% 
  mutate(status = if_else(status == "paid", 1, 0))
```

### Variable Selection

The response variable we were using is `status,` since we wanted to
explore which factors are affecting the loan repayment. For the
predictors, we are interested in the following variables:

-   `loan_amount`, because we think that the smaller loans tend to be
    more easily paid back than the larger ones.

-   `sector`, sector for which loan is requested.

-   `posted_yr`, which is the year when the loan is posted on Kiva.

-   `continent`, a new variable created based on the country where the
    borrower is located, in order to reduce the number of levels of the
    geographical variable.

-   `time`, which is a variable we created representing the time from
    when the loan is posted to when the loan is funded, in months, since
    sometimes the time it takes for the borrowers to receive the loan
    may affect their financial situation and thus affect their ability
    to repay the loan according to the terms agreed.

-   `sex`, which indicates the sex of a borrower group, where "mixed"
    means there are both males and females in a borrower group.

```{r}
d <- d %>% 
  select(loan_id, loan_amount, status, funded_amount, posted_yr, posted_mo, posted_day, funded_yr, funded_mo, funded_day, sector, location.country, borrower_m_count, borrower_f_count) %>% 
  mutate(continent = countrycode(sourcevar = location.country,
                            origin = "country.name",
                            destination = "continent"),
         time = (funded_yr - posted_yr)*365+(funded_mo - posted_mo)*30 + (funded_day - posted_day),
         sex = case_when(borrower_m_count == 0 ~ "female",
                         borrower_f_count == 0 ~ "male",
                         TRUE ~ "mixed"))
```

### Data Splitting

Next, we split our data into training set and test set, in order to
estimate the performance of our model on unseen data: data not used to
train. This is to see whether our model is generalized or overfitting.
Overfitting occurs when the model fits exactly against the training
data - it's memorizing the seen pattern rather than generalizing to new
data. We are sampling 80% of the data into the training set and the
other 20% into the testing set.

```{r}
seed <- 1
train <- sample(d$loan_id, nrow(d)*0.8)
training <- d %>% 
  filter(loan_id %in% train)
testing <-d %>% 
  filter(!loan_id %in% train)
```

## Frequentist Approach

We first fit the logistic regression model using a Frequentist approach.

### Model Fitting

We're fitting our model on the training set using the `glm()` function:

```{r}
model <- glm(status ~ loan_amount + sector + posted_yr + continent + time + sex, data = training, family = "binomial"(link = "logit")) 
```

Here we specify the family to be binomial and the link function to be
logit so that the function implements a logistic regression, described
above.

### Model Selection

To identify variables that are important in explaining variation in the
response, we perform model selection using the `step()` function.
Specifying "direction="both"" tells R to perform both forward and
backward selections. Forward selection here starts with an
intercept-only model and adds variables to it, until some stopping
criterion is met. Contrarily, backward selection starts with a full
model with all the variables included and then excludes variables from
that set until some stopping criterion is met. The default selection
criterion is $\mathrm{AIC}$: from the current model, it drops or adds
the one variable that leads to the best $\mathrm{AIC}$ improvement
(smallest $\mathrm{AIC}$).

```{r}
forback <- step(model, direction="both",trace=FALSE)
names(forback$model)
```

The selection results are stored in the `forback` list, and we can then
display only the names of selected variables instead of the whole output
by calling `names(forback$model)`. The variables selected are all except
`time`. We dropped the `time` variable from our model. The final model
is then:

```{r}
set.seed(0)
final <- glm(status ~ loan_amount + sector + posted_yr + continent + sex, data = training, family = "binomial"(link = "logit")) 
```

### Results

We can look at the summary of the model output using `tidy()` along with
functions in the $\texttt{kableExtra}$ package. The table is scrollable.

```{r}
tidy(final) %>% 
  kable(digits = 2) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  kable_paper() %>%
  scroll_box(width = "100%", height = "200px")
```

 

A brief look at the output would tell us that the term
`continentOceania` have coefficients considerably larger than others but
in the meantime have a p-value close to 1. A p-value measures the
probability of obtaining the observed results, assuming that the null
hypothesis is true. The lower the p-value, the greater the statistical
significance of the observed difference. Thus, with p-values close to 1,
these two terms are not considered statistically significant. An
intuitive reason for terms with high p-values would be that the number
of observations that fall into those categories accounts for only a very
small portion of the data.

Interpreting the coefficients in a logistic regression is a little less
straight-forward than in linear regression, but still quite simple. For
example, the coefficient for `posted_yr` is "0.44", which means that for
a given year when the loan is posted, the expected odds of the loan
getting repaid is $e^{0.50}\approx1.65$ times the odds of the loan
getting repaid if the loan is posted in the previous year.

Among all sectors, a loan in the Education sector has the highest odds
of getting repaid, while loans in the Personal Use sector are the least
likely to be repaid. Loans in the Housing sector has
$\frac{e^{0.67}}{e^{0.61}} \approx 1.06$ times the odds for loans in the
Food sector to be repaid. In terms of the continent where the loan
transaction took place, besides Oceania which has highest coefficient
but is not statistically significant, Europe is the continent where
loans generally have the highest odds of being repaid
($\frac{e^{3.63}}{e^{1.48}}\approx 8.58$ times the odds for Asia, 19.11
times the odds for Americas, and 37.71 times the odds for Africa). As
for the sex of the borrower(s), a female borrower or a female-only
borrower group has the odds of repaying the loan
$\frac{1}{e^{-0.131}}\approx 1.14$ times that for a male borrower or a
male-only borrower group.

### Model Evaluation

To evaluate our model, we plotted the ROC (*Receiver Operating
Characteristic*) curve. In a nutshell, ROC curve visualizes the
performance of a logistic model at all classification thresholds. It
plots *False positive rate* on the X-axis, which informs us about the
proportion of the negative class classified as positive
($\text{False positive rate} =\frac{\text{False positives}}{\text{False positives + True negatives (= All negatives)}}$)
and *True positive rate* on the y-axis, which informs us about the
proportion of the positive class correctly classified
($\text{True positive rate}=\frac{\text{True positives}}{\text{True positives + False negatives (= All positives)}}$).
We used `ggroc()` from the $\texttt{pROC}$ package to plot the ROC
curve.

```{r}
predicted1 <- predict(final, newdata = testing)
roc1 = roc(response = testing$status, predictor = predicted1)
ggroc(roc1, legacy.axes = TRUE) +
  labs(x = 'False-positive rate', y = 'True-positive rate', title = 'Simulated ROC curve')
```

As we can see from the graph, the curve is increasing in both
directions. This is because both False positive rate and True positive
rate are increased with lower the classification threshold which
classifies more items as positive. The closer the ROC curve is to the
top left corner of the plot, the better the model does at classifying
the data into correct categories. To quantify this, we can calculate the
AUC (area under the curve) which tells us how much of the plot is
located under the curve. AUC ranges in value from 0 to 1. A model whose
predictions are 100% wrong has an AUC of 0; one whose predictions are
100% correct has an AUC of 1. The AUC score would be 1 in that scenario.
We used the `auc()` function from the $\texttt{pROC}$ package to
calculate the AUC of the model.

```{r}
auc(testing$status,predicted1)
```

Here we got an AUC score of 0.7008, which means there is about 70%
chance that our model will be able to distinguish between positive class
(paid) and negative class (defaulted). In general, an AUC of 0.5
suggests no discrimination, 0.7 to 0.8 is considered acceptable, 0.8 to
0.9 is considered excellent, and more than 0.9 is considered
outstanding.

### Discussion

Based on our analysis, loan amount is not considered to be a factor
affecting the loan repayment status at all. We are almost certain that
borrowers in Europe is generally predicted to have a relatively high
probability of fully repay the loan among all the continents, followed
by Asia and Americas. Loans in all the sectors except for Personal Use
have a higher odds of being repaid than the Agriculture sector. Male
borrowers are predicted to be certainly less likely to repay the loan
compared to female borrowers.

## Bayesian Approach

Next, we implement an alternative to the model above using a Bayesian
approach. While a frequentist assumes that there are true values of the
parameters of the model and computes the point estimates of the
parameters, a Bayesian asserts that only data are real, and treats the
model parameters as random variables whose uncertainty can be
characterized by probability distributions.

### Model Fitting

To implement our Bayesian logistic model, we utilize an algorithm known
as Hamiltonian Monte Carlo. In particular, we use the program Stan, via
its $\texttt{R}$ interface in the $\texttt{rstanarm}$ package.

The `rstanarm` equivalent of `glm()` is `stan_glm()`, which supports
every link function that `glm()` supports. With `stan_glm()`, binomial
models with a logit link function can typically be fit slightly faster
than the identical model with a probit link.

Note that in contrast with the Frequentist procedure, in Bayesian
estimation we need to specify priors for our parameters, which permit us
to incorporate existing knowledge of the parameters into our model.

In the following code, we fit a logistic model on the same training set
as in the frequentist section, with specified link and the default
priors for the intercept and the predictor coefficients.

```{r eval=FALSE}
post <- stan_glm(status ~ loan_amount + sector + posted_yr + continent + sex, 
                 data = training,
                 family = binomial(link = "logit"), 
                 seed = seed,
                 refresh = 0,
                 cores=3, chains = 3,warmup = 500,iter = 1200)
```

We can save our models in a folder so that RStudio doesn't need to go
through the model fitting process every time we knit the document. Just
load the models from where they are stored.

```{r eval=FALSE, echo=FALSE}
save(post, file = "data/post.RData")
```

```{r include=FALSE}
load("data/post.Rdata")
load("data/post0.Rdata")
```

The `prior_summary()` function would allow us to see the info on priors
used in this model:

```{r}
prior_summary(post)
```

The default priors our model used is normal distributions with location
parameter of 0 and scale parameter of 2.5, for both the intercept and
coefficients.

In order to get an idea of which variables are associated with changes
in the probability of repayment, we draw a caterpillar plot, which
displays the posterior medians and uncertainty intervals.

We sort the predictor variables in our model `post` by their posterior
medians. To do this, we extracted the `coefficient` element from `post`
and converted it into a data frame which had only one column
"post.coefficients". We then sort the rows based on the value of the
coefficients. Next, we extract the row names except for the intercept to
pass it as the `pars` parameter in the `mcmc_intervals()` function so
that it plots the 95% uncertainty intervals computed from posterior
draws with all chains merged in the order of ascending median.

```{r}
# extract the coefficients and sort them in ascending order
coef <- data.frame(post$coefficients) %>% 
  arrange(post.coefficients)

# store the variables corresponding to the coefficients as a list
order <- rownames(coef)[-1]

# plot the sorted coefficients with uncertainty interval
cate <- mcmc_intervals(as.matrix(post), pars = order, prob = 0.95, prob_outer = 1)
```

### Results

A look at the caterpillar plot shows that `continentOceania` has
significantly larger median and uncertainty interval than other terms
and is thus compressing the plot to be uninformative, so we remove
`continentOceania` from the caterpillar plot and replot it:

```{r}
coef <- coef %>% 
  filter(rownames(.)!="continentOceania")
p <- data.frame(post) %>% 
  select(-continentOceania)
order_new <- gsub(" ",".", rownames(coef)[-1])
cate_new <- mcmc_intervals(as.matrix(p), pars = order_new, prob = 0.95, prob_outer = 1)
cate_new
```

Since the plot is in an order of the posterior median, it allows us to
directly see which predictors seem to have more or less effect on the
response variable. We can notice that the median estimate for
`loan_amount` falls exactly on the "0.0" line with no observable
uncertainty interval, indicating no relationship between loan amount and
the loan status. Among the sectors, Transportation, Manufacturing,
Construction, Retail, and Food have an uncertainty interval entirely
positive; Health, Housing, Arts, and Services has a positive median but
some portion of the uncertainty interval falls on the negative part;
Personal Use has a negative median but some portion of the uncertainty
interval falls on the positive part. Overall, the larger medians also
come up wider uncertainty intervals, except for `continentAsia`, which
has a fourth large median but nearly 0 uncertainty interval.

### Model Evaluation

```{r}
(loo1 <- loo(post, save_psis = TRUE, k_threshold = 0.7))
```

In the code chunk above, we assessed the strength of our model via its
posterior predictive LOOCV (Leave One Out Cross-Validation).
Cross-validation is a technique for evaluating models by training the
models on subsets of the available input data and evaluating them on the
complementary subset of the data. LOOCV is a type of cross-validation
approach in which each observation is considered as the validation set
and the rest ($N-1$) observations are considered as the training set.
PSIS-LOO CV is and efficient approximate LOOCV for Bayesian models using
Pareto smoothed importance sampling
([**PSIS**](https://www.rdocumentation.org/link/PSIS?package=loo&version=2.5.1&to=%3Dpsis)).
We can see from the output that PSIS-LOO result is reliable as all
Pareto k estimates are small (k\< 0.5). However as we know, this
accuracy rate is quite meaningless unless we have something to compare
it to. So we created a baseline model with no predictors for comparison:

```{r eval=FALSE}
post0 <- stan_glm(status ~ 1, data = training,
                 family = binomial(link = "logit"), 
                 seed = seed,
                 refresh = 0,
                 cores=3, chains = 3, warmup = 500,iter = 1200)
save(post0, file = "data/post0.RData")
```

```{r}
(loo0 <- loo(post0, save_psis = T))
```

```{r}
rstanarm::compare_models(loo0, loo1)
```

Since difference is positive (38.6), the expected predictive accuracy
for the second model (post) is higher.

Below, we compute posterior predictive probabilities of the linear
predictor via the `posterior_linpred()` function provided in the
$\texttt{rstanarm}$ package. This function will extract posterior draws
from the linear predictor. If we used a link function, then specifying
the transform argument as `TRUE` will return the predictor as
transformed via the inverse-link.

```{r}
preds <- posterior_linpred(post, transform=TRUE)
pred <- colMeans(preds)
```

We calculate these posterior predictive probabilities in order to
determine the classification accuracy of our model. If the posterior
probability of paying back the loan for an borrower is greater or equal
to 0.5, then we would predict that observation to be a repaid loan (and
similarly for less than 0.5). For each observation, we can compare the
posterior prediction to the actual observed value. The proportion of
times we correctly predict an individual (i.e. prediction = 0 and
observation = 0 or prediction = 1 and observation = 1) is our
classification accuracy.

```{r}
pr <- as.integer(pred >= 0.5)
round(mean(xor(pr,as.integer(training$status==0))),3)
```

We should also evaluate the classification accuracy of our model on
unseen data. This can be done by using a test dataset or via a LOOCV
approach. Since we've talked about the former approach in the
frequentist section, here we would use the latter approach to illustrate
the function `E_loo()`, which uses importance weights generated from the
`loo()` function. Then we would compare the accuracy for the bayesian
and frequentist models on the same test data using the former approach.

```{r}
ploo = E_loo(preds, loo1$psis_object, type = "mean", log_ratios = -log_lik(post))$value
round(mean(xor(ploo > 0.5, as.integer(training$status == 0))), 3)
```

The accuracy is 0.977, which is very high. However, this does not
necessarily mean our model is doing great in prediction. Instead, it is
probably just due to the high unbalance of the data, with almost all
observations having the value "paid" for the response variable.

```{r}
qplot(pred, ploo,geom=c("point", "smooth")) +
  ggtitle("LOO probability vs. posterior predictive probability")
```

In the plot above we can see the small difference in posterior
predictive probabilities and LOO probabilities.

We can again use ROC and AUC to evaluate this model. First, we need to
prepare a test data set. Here we are extracting data from the original
data set that are not in the sample.

```{r}
predicted <- predict(post, newdata=testing)
```

Here's the ROC curve of our model on the testing data:

```{r}
roc = roc(response = testing$status, predictor = predicted)
ggroc(roc, legacy.axes = TRUE) +
  labs(x = 'False-positive rate', y = 'True-positive rate', title = 'Simulated ROC curve')
```

```{r}
auc(testing$status,predicted)
```

We got an AUC score of 0.7097, which is only slightly higher than the
one for the frequentist model (0.7008).

### Discussion

Among all the terms, continentAsia is the only one that has great effect
on the response variable together with a super narrow uncertainty
interval. We can safely conclude that borrowers in Asia are generally
predicted to have a relatively high probability of fully repay the loan.
For all the sectors, each level either has a wide uncertainty interval
or a small posterior median, making it hard to conclude any significant
insights. Male borrowers are predicted to be certainly less likely to
repay the loan compared to female borrowers.

## Conclusion

Same for the frequentist model and bayesian model, loan amount is not
considered to be a factor affecting the loan repayment status at all.
The probability of loans getting repaid rather than not repaid is
predicted to be increasing over years by both models, which is generally
a good sign for the loan market as well as the economy. Both models
suggests Oceania to have the highest odds ratio for the loan to be
repaid while Africa has the lowest odds ratio, followed by Europe, Asia,
America, and then Africa; they also have a high uncertainty on the
coefficients for Oceania. Loans in the Personal Use sector is predicted
to be the sector that has the lowest odds of being repaid, while
Wholesale and Education are predicted to have the highest odds, by both
models. While the frequentist model suggest a higher odds for female
borrowers to repay the loan than borrower groups of mixed gender, the
bayesian model suggests the opposite, but the difference is not
statistically significant. When evaluating on the testing set, the
bayesian model slightly outperforms the frequentist model, with an AUC
score only about 0.009 higher.
